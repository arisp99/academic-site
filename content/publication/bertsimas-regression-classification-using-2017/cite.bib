@inproceedings{bertsimasRegressionClassificationUsing2017,
 abstract = {Current state-of-the-art decision tree algorithms, such as Classification and Regression Trees (CART), build the decision tree using a recursive approach based on a greedy heuristic. We study the benefits of an optimal decision tree approach, which creates the entire decision tree at once using Mixed Integer Optimization (MIO). While such problems are known to be hard to solve for large instances, we leverage modern solver techniques that are able to obtain near-optimal solutions in a reasonable amount of time. The methodology is able to handle both single-feature splits, as in CART, and also hyperplane splits that use multiple features. We test optimal regression trees on a host of synthetic datasets and optimal classification tress on a novel application concerning the usage of CT imagining to diagnose head injuries in children. Our results demonstrate that optimal trees lead to a significantly greater accuracy than CART.},
 author = {Bertsimas, Dimitris and Dunn, Jack and Paschalidis, Aris},
 booktitle = {2017 IEEE MIT Undergraduate Research Technology Conference (URTC)},
 doi = {10.1109/URTC.2017.8284195},
 file = {files/207/8284195.html},
 keywords = {CART,Classification,Classification and Regression Trees,Complexity theory,Data models,decision trees,Decision trees,injuries,Integer Optimization,integer programming,Measurement uncertainty,medical diagnostic computing,Mixed Integer Optimization,optimal decision tree approach,Optimized production technology,pattern classification,recursive approach,Regression,regression analysis,Regression tree analysis,Training},
 month = {November},
 pages = {1--4},
 title = {Regression and Classification Using Optimal Decision Trees},
 year = {2017}
}

